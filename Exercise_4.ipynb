{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "**Match searches with bookings**\n",
    "\n",
    "- For every search in the searches file, find out whether the search ended up in a booking or not (using the info in the bookings file). For instance, search and booking origin and destination should match.\n",
    "- For the bookings file, origin and destination are the columns `dep_port` and `arr_port`, respectively.\n",
    "- Generate a CSV file with the search data, and an additional field, containing 1 if the search ended up in a booking, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "#pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searches_data_preprocessing(df, columns_to_clean): \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    for column in columns_to_clean:\n",
    "        df[column] = df[column].str.strip()\n",
    "    \n",
    "        if 'Date' not in column:\n",
    "            df[column] = df[column].str.upper()\n",
    "            # Para saber si hay lengths superiores a 3 sin que nos de error por los missing values    \n",
    "            cell_lengths = df[column].map(lambda x: len(x) if not isinstance(x, float) else x)\n",
    "            cell_lengths_notna = cell_lengths[cell_lengths.notna()]\n",
    "            cell_lengths_sum = (cell_lengths_notna != 3.0).sum()\n",
    "            if cell_lengths_sum != 0:\n",
    "                print(f'Alert! There are `{column}` values with length different than 3. Dropping them..')\n",
    "\n",
    "                mask = cell_lengths_notna != 3.0\n",
    "                wrong_data = cell_lengths_notna[mask]\n",
    "                print(wrong_data)\n",
    "                df.drop(index=wrong_data.index, inplace=True)\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'Date':'object',\n",
    "          'Time':'object',\n",
    "          'TxnCode':'object',\n",
    "          'OfficeID':'object',\n",
    "          'Country':'object',\n",
    "          'Origin':'object',\n",
    "          'Destination':'object',\n",
    "          'RoundTrip':'int64',\n",
    "          'NbSegments':'int64',\n",
    "          'Seg1Departure':'object',\n",
    "          'Seg1Arrival':'object',\n",
    "          'Seg1Date':'object',\n",
    "          'Seg1Carrier':'object',\n",
    "          'Seg1BookingCode':'object',\n",
    "          'Seg2Departure':'object',\n",
    "          'Seg2Arrival':'object',\n",
    "          'Seg2Date':'object',\n",
    "          'Seg2Carrier':'object',\n",
    "          'Seg2BookingCode':'object',\n",
    "          'Seg3Departure':'object',\n",
    "          'Seg3Arrival':'object',\n",
    "          'Seg3Date':'object',\n",
    "          'Seg3Carrier':'object',\n",
    "          'Seg3BookingCode':'object',\n",
    "          'Seg4Departure':'object',\n",
    "          'Seg4Arrival':'object',\n",
    "          'Seg4Date':'object',\n",
    "          'Seg4Carrier':'object',\n",
    "          'Seg4BookingCode':'object',\n",
    "          'Seg5Departure':'object',\n",
    "          'Seg5Arrival':'object',\n",
    "          'Seg5Date':'object',\n",
    "          'Seg5Carrier':'object',\n",
    "          'Seg5BookingCode':'object',\n",
    "          'Seg6Departure':'object',\n",
    "          'Seg6Arrival':'object',\n",
    "          'Seg6Date':'object',\n",
    "          'Seg6Carrier':'object',\n",
    "          'Seg6BookingCode':'object',\n",
    "          'From':'object',\n",
    "          'IsPublishedForNeg':'int64',\n",
    "          'IsFromInternet':'int64',\n",
    "          'IsFromVista':'int64',\n",
    "          'TerminalID':'object',\n",
    "          'InternetOffice':'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 1, size of chunk 100000\n",
      "Chunk: 2, size of chunk 99999\n",
      "Chunk: 3, size of chunk 100000\n",
      "Chunk: 4, size of chunk 100000\n",
      "Chunk: 5, size of chunk 100000\n",
      "Chunk: 6, size of chunk 99999\n",
      "Chunk: 7, size of chunk 100000\n",
      "Chunk: 8, size of chunk 100000\n",
      "Chunk: 9, size of chunk 100000\n",
      "Chunk: 10, size of chunk 99999\n"
     ]
    }
   ],
   "source": [
    "columns_to_clean = ['Date', 'Seg1Departure', 'Seg1Arrival', 'Seg1Date', \n",
    "                 'Seg2Departure', 'Seg2Arrival', 'Seg2Date', \n",
    "                 'Seg3Departure', 'Seg3Arrival', 'Seg3Date', \n",
    "                 'Seg4Departure', 'Seg4Arrival', 'Seg4Date', \n",
    "                 'Seg5Departure', 'Seg5Arrival', 'Seg5Date', \n",
    "                 'Seg6Departure', 'Seg6Arrival', 'Seg6Date',\n",
    "                ]\n",
    "\n",
    "data_iterator = pd.read_csv(\"../challenge/searches.csv.bz2\", \n",
    "                            chunksize=10**5, \n",
    "                            sep='^', \n",
    "                            compression='bz2',\n",
    "                            nrows=10**6,\n",
    "                            low_memory=False,\n",
    "                            #dtype=dtypes,\n",
    "                            #na_values=[np.nan],\n",
    "                            memory_map=True\n",
    "                           )\n",
    "\n",
    "searches = pd.DataFrame()\n",
    "for i, data_chunk in enumerate(data_iterator):\n",
    "    data_chunk = searches_data_preprocessing(data_chunk, columns_to_clean)\n",
    "    #data_chunk.reset_index(inplace=True)\n",
    "    data_chunk = data_chunk\n",
    "    searches = searches.append(data_chunk)\n",
    "    print(\"Chunk: %d, size of chunk %d\"%(i+1, data_chunk.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999997, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookings_data_preprocessing(df): \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].str.strip()\n",
    "    \n",
    "        if 'port' in column:\n",
    "            df[column] = df[column].str.upper()\n",
    "            \n",
    "            # Para saber si hay lengths superiores a 3 sin que nos de error por los missing values\n",
    "            cell_lengths = df[column].map(lambda x: len(x) if not isinstance(x, float) else x)\n",
    "            cell_lengths_notna = cell_lengths[cell_lengths.notna()]\n",
    "            cell_lengths_sum = (cell_lengths_notna != 3.0).sum()\n",
    "            if cell_lengths_sum != 0:\n",
    "                print(f'Alert! There are `{column}` values with length different than 3. Dropping them..')\n",
    "\n",
    "                mask = cell_lengths_notna != 3.0\n",
    "                wrong_data = cell_lengths_notna[mask]\n",
    "                print(wrong_data)\n",
    "                df.drop(index=wrong_data.index, inplace=True)\n",
    "        else:\n",
    "            df[column] = df[column].str.split().str[0]\n",
    "        \n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 1, size of chunk 71284\n",
      "Chunk: 2, size of chunk 71096\n",
      "Chunk: 3, size of chunk 70668\n",
      "Chunk: 4, size of chunk 70846\n",
      "Chunk: 5, size of chunk 71757\n",
      "Chunk: 6, size of chunk 72056\n",
      "Chunk: 7, size of chunk 71845\n",
      "Chunk: 8, size of chunk 71992\n",
      "Chunk: 9, size of chunk 72239\n",
      "Chunk: 10, size of chunk 72088\n"
     ]
    }
   ],
   "source": [
    "data_iterator = pd.read_csv(\"../challenge/bookings.csv.bz2\", \n",
    "                            chunksize = 10**5, \n",
    "                            sep = '^', \n",
    "                            compression = 'bz2',\n",
    "                            nrows = 10**6,\n",
    "                            usecols = ['dep_port', \n",
    "                                       'arr_port', \n",
    "                                       'brd_time           ',\n",
    "                                       'cre_date           ',\n",
    "                                      ],\n",
    "                            low_memory=False\n",
    "                           )\n",
    "\n",
    "bookings = pd.DataFrame()\n",
    "for i, data_chunk in enumerate(data_iterator):\n",
    "    data_chunk = bookings_data_preprocessing(data_chunk)\n",
    "    #data_chunk.reset_index(inplace=True)\n",
    "    data_chunk['Booking'] = 1\n",
    "    bookings = bookings.append(data_chunk)\n",
    "    print(\"Chunk: %d, size of chunk %d\"%(i+1, data_chunk.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715871, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar de nuevo los duplicados y eliminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56873"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings.drop_duplicates(inplace=True)\n",
    "bookings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.drop_duplicates(inplace=True)\n",
    "searches.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658998, 5)\n",
      "(458999, 45)\n"
     ]
    }
   ],
   "source": [
    "print(bookings.shape)\n",
    "print(searches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns_bookings = [['Date', 'Seg1Departure', 'Seg1Arrival', 'Seg1Date', 'booking'], \n",
    "                        ['Date', 'Seg2Departure', 'Seg2Arrival', 'Seg2Date', 'booking'],\n",
    "                        ['Date', 'Seg3Departure', 'Seg3Arrival', 'Seg3Date', 'booking'],\n",
    "                        ['Date', 'Seg4Departure', 'Seg4Arrival', 'Seg4Date', 'booking'],\n",
    "                        ['Date', 'Seg5Departure', 'Seg5Arrival', 'Seg5Date', 'booking'],\n",
    "                        ['Date', 'Seg6Departure', 'Seg6Arrival', 'Seg6Date', 'booking'],\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458999, 46)\n",
      "(458999, 47)\n",
      "(458999, 48)\n",
      "(458999, 49)\n",
      "(458999, 50)\n",
      "(458999, 51)\n"
     ]
    }
   ],
   "source": [
    "for i, lista in enumerate(new_columns_bookings):\n",
    "    bookings.columns = lista\n",
    "\n",
    "    searches = searches.merge(bookings, \n",
    "                              how = 'left', \n",
    "                              on = lista[:4], \n",
    "                              suffixes=(i, i+1),\n",
    "                             )\n",
    "    print(searches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458999 entries, 0 to 458998\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   booking1  530 non-null    float64\n",
      " 1   booking2  214 non-null    float64\n",
      " 2   booking3  36 non-null     float64\n",
      " 3   booking4  30 non-null     float64\n",
      " 4   booking5  3 non-null      float64\n",
      " 5   booking6  1 non-null      float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 24.5 MB\n"
     ]
    }
   ],
   "source": [
    "searches.iloc[:, -6:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches.iloc[:, -6:] = searches.iloc[:, -6:].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458999 entries, 0 to 458998\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   booking1  458999 non-null  float64\n",
      " 1   booking2  458999 non-null  float64\n",
      " 2   booking3  458999 non-null  float64\n",
      " 3   booking4  458999 non-null  float64\n",
      " 4   booking5  458999 non-null  float64\n",
      " 5   booking6  458999 non-null  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 24.5 MB\n"
     ]
    }
   ],
   "source": [
    "searches.iloc[:, -6:].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "booking1    530.0\n",
       "booking2    214.0\n",
       "booking3     36.0\n",
       "booking4     30.0\n",
       "booking5      3.0\n",
       "booking6      1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.iloc[:, -6:].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la nueva columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches['Booking'] = 0\n",
    "for column in searches.columns[-7:-1]:\n",
    "    searches['Booking'] += searches[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814.0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches['Booking'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.iloc[:, -7:-1].sum().sum() #comprobacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas sobrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['booking1', 'booking2', 'booking3', 'booking4', 'booking5', 'booking6'], dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.columns[-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458999, 52)\n",
      "(458999, 46)\n"
     ]
    }
   ],
   "source": [
    "print(searches.shape)\n",
    "searches.drop(columns=searches.columns[-7:-1], inplace=True)\n",
    "print(searches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches['Booking'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cre_date               0\n",
       "dep_port               0\n",
       "arr_port               0\n",
       "brd_time               0\n",
       "Booking                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                      0\n",
       "Time                      0\n",
       "TxnCode                   0\n",
       "OfficeID                  0\n",
       "Country                  51\n",
       "Origin                    0\n",
       "Destination               0\n",
       "RoundTrip                 0\n",
       "NbSegments                0\n",
       "Seg1Departure             0\n",
       "Seg1Arrival               0\n",
       "Seg1Date               1282\n",
       "Seg1Carrier          284543\n",
       "Seg1BookingCode      411897\n",
       "Seg2Departure        132239\n",
       "Seg2Arrival          132239\n",
       "Seg2Date             133765\n",
       "Seg2Carrier          337279\n",
       "Seg2BookingCode      418449\n",
       "Seg3Departure        434559\n",
       "Seg3Arrival          434559\n",
       "Seg3Date             434691\n",
       "Seg3Carrier          435786\n",
       "Seg3BookingCode      437078\n",
       "Seg4Departure        439480\n",
       "Seg4Arrival          439480\n",
       "Seg4Date             439599\n",
       "Seg4Carrier          439648\n",
       "Seg4BookingCode      439945\n",
       "Seg5Departure        455221\n",
       "Seg5Arrival          455221\n",
       "Seg5Date             455249\n",
       "Seg5Carrier          455244\n",
       "Seg5BookingCode      455309\n",
       "Seg6Departure        456732\n",
       "Seg6Arrival          456732\n",
       "Seg6Date             456754\n",
       "Seg6Carrier          456735\n",
       "Seg6BookingCode      456776\n",
       "From                   8204\n",
       "IsPublishedForNeg         0\n",
       "IsFromInternet            0\n",
       "IsFromVista               0\n",
       "TerminalID                0\n",
       "InternetOffice            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Column|NaN|\n",
    "|:---:|:---:|\n",
    "|Date|0|\n",
    "|Seg1Departure|0|\n",
    "|Seg1Arrival|0|\n",
    "|Seg1Date|1282|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Column|NaN|\n",
    "|:---:|:---:|\n",
    "|Date|0|\n",
    "|Seg2Departure|132239|\n",
    "|Seg2Arrival|132239|\n",
    "|Seg2Date|133765|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pdemos observar el mismo patron en todos los segmentos, `SegnDeparture` y `SegnArribal` tienen la misma cantidad de missing values, mientras que `SegnDate` tiene unos pocos mas. \n",
    "\n",
    "Ello significa que si un cierto dia se reservan vuelos de una ciudad a otra en dias distintos, estos tendran los mismos datos en las columnas relevantes para hacer el join.\n",
    "\n",
    "Esto lo vamos a dejar para el finde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
